{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JE_Exam-Final.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM/Olc4ognuZZCY0PP4GxGC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayaemekar/CSCI-611-AppiledMachineLearning/blob/main/JE_Exam_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0EsfRImkzTv"
      },
      "source": [
        "#Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6dEJdMxk2JW"
      },
      "source": [
        "# linear algebra\n",
        "import numpy as np \n",
        "\n",
        "# data processing\n",
        "import pandas as pd \n",
        "\n",
        "# data visualization\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import style\n",
        "\n",
        "# data preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Algorithms\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "#Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# Model evaluation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Create a classification report and confusion matrix for the model.\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Hyperparameter tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Remove warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4UuDTZYkA9l"
      },
      "source": [
        "#SECTION 1 - DATA INTERPRETATION "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo2QaCbWkefv"
      },
      "source": [
        "##1. DATASET DIMENSIONS & TYPES\n",
        "<br>a  How many exemplars are in the dataset? _______\n",
        "<br>b How many total features? ________\n",
        "<br>c List the unique data types? _________ _________ __________"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOiSSqoDkCdn"
      },
      "source": [
        "#Load the data\n",
        "titanic = pd.read_csv('/content/titanic_train_exam.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_In1meFngW8"
      },
      "source": [
        "How many exemplars are in the dataset?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwHmmIT8njJF"
      },
      "source": [
        "#How many exemplars are in the dataset?\n",
        "print ('Exemplars in the dataset are ',len(titanic))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmx5ewq3n4IA"
      },
      "source": [
        "How many total features?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_4GZM2_n7iy"
      },
      "source": [
        "#How many total features?\n",
        "print ('Total features in the dataset are ',titanic.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQvCc_KMpQkr"
      },
      "source": [
        "List the unique data types? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St7wg9wqpRfG"
      },
      "source": [
        "#List the unique data types? \n",
        "print ('Total unique data types the dataset are \\n ',titanic.dtypes.unique)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgiPE9nVr2XO"
      },
      "source": [
        "##2. EXPLORE NULL VALUES\n",
        "\n",
        "<br>a Display the first four exemplars in this dataset. Do you see any null values displayed?\n",
        "<br>b Visualize the null features using a graph of your choice. Which features stand out?\n",
        "<br>c For the feature with the greatest number of nulls, how many rows are affected? \n",
        "<br>d Which Passenger Class has the greatest number of null valued cabins?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E5Wqr7csJI2"
      },
      "source": [
        "Display the first four exemplars in this dataset. Do you see any null values displayed?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bh3DF_TsKJL"
      },
      "source": [
        "#Display the first four exemplars in this dataset. Do you see any null values displayed?\n",
        "titanic.head(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eserIFqsQWT"
      },
      "source": [
        "Yes , we can see null values in column and Age Cabin\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNWKtJJ-sdRL"
      },
      "source": [
        "Visualize the null features using a graph of your choice. Which features stand out?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7DFqPiFseGP"
      },
      "source": [
        "#draw a bar plot of survival by sex\n",
        "sns.barplot(x=\"Sex\", y=\"Survived\", data=titanic)\n",
        "\n",
        "#print percentages of females vs. males that survive\n",
        "print(\"Percentage of females who survived:\", titanic[\"Survived\"][titanic[\"Sex\"] == 'female'].value_counts(normalize = True)[1]*100)\n",
        "\n",
        "print(\"Percentage of males who survived:\", titanic[\"Survived\"][titanic[\"Sex\"] == 'male'].value_counts(normalize = True)[1]*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMq_vnG0vLiQ"
      },
      "source": [
        "Visualize the null features using a graph of your choice. Which features stand out?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ciciuk_Qs7KX"
      },
      "source": [
        "#Visualize the null features using a graph of your choice. Which features stand out?\n",
        "\n",
        "#Plot the Cabin column\n",
        "titanic[\"Deck\"]=titanic.Cabin.str[0]\n",
        "titanic[\"Deck\"].unique() # 0 is for null values\n",
        "\n",
        "# count plot on single categorical variable\n",
        "sns.countplot(x ='Deck', data = titanic)\n",
        " \n",
        "# Show the plot\n",
        "plt.show()                    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHbaq70_vI-C"
      },
      "source": [
        "For the feature with the greatest number of nulls, how many rows are affected? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWIdFbibvX5A"
      },
      "source": [
        "#Below are the missing values from each column\n",
        "titanic.isnull().sum()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiJuvIfVvmWI"
      },
      "source": [
        "print('Cabin feature is having highest number of null values = 682')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g04nCQnavl5y"
      },
      "source": [
        "Which Passenger Class has the greatest number of null valued cabins?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YEl4baQvtqy"
      },
      "source": [
        "sns.factorplot('Deck', col = 'Pclass', data = titanic, kind = 'count')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPMY6YAQx9uF"
      },
      "source": [
        "##TARGET CLASS - Survived\n",
        "\n",
        "<br>a How many Survivors are in the dataset? Non-survivors? \n",
        "<br>b Compare the number of survivors to non-survivors in a labeled graph.\n",
        "<br>c Expand the graph to include survivor information by gender.\n",
        "<br>d Expand the graph to include survivor information by Passenger class.\n",
        "<br>e Do these graphs provide a general picture of survival by gender or Pclass, if so, what? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do7JZOFKzrjB"
      },
      "source": [
        "print('Survived people ', len(titanic[titanic['Survived'] ==1]))\n",
        "print('Not Survived people ', len(titanic[titanic['Survived'] == 0]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8iBHkpf08ol"
      },
      "source": [
        "Compare the number of survivors to non-survivors in a labeled graph. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poWpVTHsyKaq"
      },
      "source": [
        "#How many Survivors are in the dataset? Non-survivors?\n",
        "\n",
        "# count plot on single categorical variable\n",
        "sns.countplot(x ='Survived', data = titanic)\n",
        " \n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K-W6exU0-Vq"
      },
      "source": [
        "Expand the graph to include survivor information by gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snZhOvS81CjP"
      },
      "source": [
        "# Survival by gender \n",
        "sns.countplot(x ='Survived',hue = 'Sex', data = titanic)\n",
        "plt.ylabel('Survival Probability')\n",
        "plt.title('Survival Probability by Sex',fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD7C0BSz1zyQ"
      },
      "source": [
        "Expand the graph to include survivor information by Passenger class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl0vXPF110-f"
      },
      "source": [
        "# Survival by Pclass \n",
        "sns.countplot(x ='Survived',hue = 'Pclass', data = titanic)\n",
        "plt.ylabel('Survival Probability')\n",
        "plt.title('Survival Probability by Passenger Class',fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmRpi_m32FfF"
      },
      "source": [
        "# Survival by gender and passenger class\n",
        "graph = sns.factorplot(x = 'Pclass', y = 'Survived',kind = 'bar',hue = 'Sex', data = titanic)\n",
        "graph.despine(left = True)\n",
        "plt.ylabel('Survival Probability')\n",
        "plt.title('Survival Probability by Sex and Passenger Class',fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh9TvFOZ2NnN"
      },
      "source": [
        "Do these graphs provide a general picture of survival by gender or Pclass, if so, what? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8qNX84h2QHv"
      },
      "source": [
        "Yes these graph shows that survival rate for class 1 is higher\n",
        "while with gender survival rate for female is more.\n",
        "\n",
        "Combine both of these things survival rate for females in the first class is more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZWpGaRY2vO5"
      },
      "source": [
        "## DISTRIBUTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-tMXwJE2z1L"
      },
      "source": [
        "<br>a Create a visual to graph the Age distribution.\n",
        "<br>b What is the min? _____ max? _____ mean? ______ and mode age? _____\n",
        "<br>c Use a labeled graph of your choice to show the distribution of Fares.\n",
        "<br>d Describe the full range of statistics for Fares."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io37Xhbr3ANX"
      },
      "source": [
        "Create a visual to graph the Age distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j76gsMdH2lu-"
      },
      "source": [
        "\n",
        "plt.figure(1)\n",
        "age  = titanic.loc[titanic.Survived == 1, 'Age']\n",
        "plt.title('The histogram of the age groups of the people that had survived')\n",
        "plt.hist(age, np.arange(0,100,10))\n",
        "plt.xticks(np.arange(0,100,10))\n",
        "\n",
        "\n",
        "plt.figure(2)\n",
        "age  = titanic.loc[titanic.Survived == 0, 'Age']\n",
        "plt.title('The histogram of the age groups of the people that coudn\\'t survive')\n",
        "plt.hist(age, np.arange(0,100,10))\n",
        "plt.xticks(np.arange(0,100,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OOe4yhK56sP"
      },
      "source": [
        "What is the min? _____ max? _____ mean? ______ and mode age?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5T1LJqD58IN"
      },
      "source": [
        "# using groupby function with aggregation\n",
        "# to get mean, min and max values\n",
        "result = titanic.groupby('Survived').agg({'Age': ['mean', 'min', 'max']})\n",
        "  \n",
        "print(\"Mean, min, and max values of Survived grouped by Age\")\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt0BcB2J7CWa"
      },
      "source": [
        "Use a labeled graph of your choice to show the distribution of Fares."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQTnxGif7Dar"
      },
      "source": [
        "#Use a labeled graph of your choice to show the distribution of Fares.\n",
        "\n",
        "plt.subplots(figsize=(15,10))\n",
        "\n",
        "ax=sns.kdeplot(titanic.loc[(titanic['Survived'] == 0),'Fare'],color='r',shade=True,label='Not Survived')\n",
        "ax=sns.kdeplot(titanic.loc[(titanic['Survived'] == 1),'Fare'],color='b',shade=True,label='Survived' )\n",
        "plt.title('Fare Distribution Survived vs Non Survived',fontsize=25)\n",
        "plt.ylabel('Frequency of Passenger Survived')\n",
        "plt.xlabel('Fare',fontsize=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUbFXEGu8Khh"
      },
      "source": [
        "Describe the full range of statistics for Fares."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-Ys1jx88Lfs"
      },
      "source": [
        "#Plot the Prices Paid Of Each Class\n",
        "plt.scatter(titanic['Fare'], titanic['Pclass'],  color = 'purple', label='Passenger Paid')\n",
        "plt.ylabel('Class')\n",
        "plt.xlabel('Price / Fare')\n",
        "plt.title('Price Of Each Class')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJgMVn9uA1iN"
      },
      "source": [
        "#SECTION 2 – PREPROCESSING the DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZFTLdF3A2w1"
      },
      "source": [
        "##NULL VALUES\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_D-GZD5A9Qq"
      },
      "source": [
        "a For any feature with > 50% null values, drop the feature from the dataset. What, if any,\n",
        "feature(s) did you drop? \n",
        "\n",
        "Yes I am going to drop the Cabin and Deck feature from the data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSY5GQtQA5e-"
      },
      "source": [
        "#For any feature with > 50% null values, drop the feature from the dataset. \n",
        "#Percentage missing values from titanic data for each table\n",
        "total = titanic.isnull().sum().sort_values(ascending=False)\n",
        "percent = titanic.isnull().sum()/titanic.isnull().count()*100\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Total', '%'])\n",
        "missing_data.head(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw_503PqBbxe"
      },
      "source": [
        "From above data we can analyze that\n",
        "\n",
        "The Embarked feature has only 2 missing values, which can easily be filled.\n",
        "1. 'Age' feature, which has 175 missing values.It will be much more tricky, to deal with the Age feature.\n",
        "2. The ‘Cabin’ feature needs further investigation, but it looks like that we might want to drop it from the dataset, since 77 % of it are missing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIn9_4emBoL3"
      },
      "source": [
        "Also, Looking at the titanic data The features contribute to a high survival rate are everything except ‘PassengerId’, ‘Ticket’ and ‘Name’."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwi-Pi-EBya2"
      },
      "source": [
        "For any feature with < 10% null values, remove the associated exemplars from the dataset.\n",
        "How many, if any, rows did you remove?\n",
        "\n",
        "<br> Yes. I removed the rows where less than 10% null values are there"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jV4ypmSVDOdG"
      },
      "source": [
        "Use a seaborn boxplot (or other labeled graph of choice) to visualize the Age distribution per\n",
        "Passenger class. What do you observe about the Age/Pclass relationship? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViSLv-yUFLLr"
      },
      "source": [
        "# Survival by gender and passenger class\n",
        "for x in [titanic]:\n",
        "    x['Age_bin']=np.nan\n",
        "    for i in range(8,0,-1):\n",
        "        x.loc[ x['Age'] <= i*10, 'Age_bin'] = i\n",
        "titanic[[\"Age\" , \"Age_bin\"]].head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGXp96VtDPWU"
      },
      "source": [
        "sns.factorplot('Age_bin','Survived', col='Pclass', row = 'Sex',kind=\"bar\", data=titanic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHfrnVm8FpAt"
      },
      "source": [
        "Apply imputation (based on Passenger class mean) to fill empty age values. Show your code.\n",
        "Verify results. What is the mean age per class? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZNTTub8FqJS"
      },
      "source": [
        "# using groupby function with aggregation\n",
        "# to get mean, min and max values\n",
        "result = titanic.groupby('Pclass').agg({'Age': ['mean', 'min', 'max']})\n",
        "  \n",
        "print(\"Mean, min, and max values of Survived grouped by Pclass\")\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0uz_2y5Gi7M"
      },
      "source": [
        "Filling Null values for age"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTLDY_2vGnN5"
      },
      "source": [
        "# replacing na values in college with No college\n",
        "#titanic[\"Age\"].fillna(\"37\", inplace = True)\n",
        "\n",
        "titanic.Age = np.where(titanic.Pclass==1, titanic[\"Age\"].fillna(\"38\"), titanic.Age)\n",
        "titanic.Age = np.where(titanic.Pclass==2, titanic[\"Age\"].fillna(\"30\"), titanic.Age)\n",
        "titanic.Age = np.where(titanic.Pclass==3, titanic[\"Age\"].fillna(\"25\"), titanic.Age)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PahzsCPYI2DD"
      },
      "source": [
        "titanic.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_04mcZ9zJJw3"
      },
      "source": [
        "##6. CATEGORICAL DATA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhnmFvjzJuG6"
      },
      "source": [
        "We will want to keep the categorical features that can be reasonably encoded and have intrinsic\n",
        "value. Which categorical feature have you already observed to be highly correlated with\n",
        "Survival? _______ . Encode that one. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCNSlmx_J3iJ"
      },
      "source": [
        "From above data we can analyze that\n",
        "\n",
        "The Embarked feature has only 2 missing values, which can easily be filled.\n",
        "\n",
        "1. 'Age' feature, which has 175 missing values.which is filled using the mean value of Pclass.\n",
        "2. The ‘Cabin’ feature needs further investigation, but it looks like that we might want to drop it from the dataset, since 77 % of it are missing. and that doesnt count for surrival prediction so decided to drop the column\n",
        "\n",
        "Also, Looking at the titanic data The features contribute to a high survival rate are everything except ‘PassengerId’, ‘Ticket’ and ‘Name’.\n",
        "\n",
        "Lets drop the column which are not contributing to high surrival rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OI_LEuLJLBl"
      },
      "source": [
        "titanic_old =titanic\n",
        "# Drop the columns\n",
        "titanic = titanic.drop([ 'Name', 'Ticket', 'Cabin','PassengerId','Age_bin','Deck'], axis=1)\n",
        "\n",
        "#Remove the rows with missing values\n",
        "titanic = titanic.dropna(subset =['Embarked'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAe_Br0jLBdB"
      },
      "source": [
        "#Count the NEW number of rows and columns in the data set\n",
        "titanic.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTGLoyuiLEVu"
      },
      "source": [
        "titanic.head(6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUIhCw7rLe-q"
      },
      "source": [
        "#Print the unique values in the columns\n",
        "print(titanic['Sex'].unique())\n",
        "print(titanic['Embarked'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDvwA6GkLv6L"
      },
      "source": [
        "Encoding categorical data values (Transforming object data types to integers)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STGffoUOLszh"
      },
      "source": [
        "#Print the NEW unique values in the columns\n",
        "print(titanic['Sex'].unique())\n",
        "print(titanic['Embarked'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj3jolCSLktV"
      },
      "source": [
        "Label Encoding \n",
        "Encoding categorical data values (Transforming object data types to integers)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FpmTfqFML4C"
      },
      "source": [
        "#Encoding categorical data values (Transforming object data types to integers)\n",
        "labelencoder = LabelEncoder()\n",
        "\n",
        "titanic.iloc[:,2]= labelencoder.fit_transform(titanic.iloc[:,2].values) #Encode sex column\n",
        "titanic.iloc[:,7]= labelencoder.fit_transform(titanic.iloc[:,7].values) #Encode embarked\n",
        "\n",
        "#Print the NEW unique values in the columns\n",
        "print(titanic['Sex'].unique())\n",
        "print(titanic['Embarked'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo9MPasb_M_l"
      },
      "source": [
        "#SECTION 3 – MODELING "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1qO7-aM_TaL"
      },
      "source": [
        "##TRAIN-TEST SPLIT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8EctTBi_QOc"
      },
      "source": [
        "#TRAIN-TEST SPLIT\n",
        "\n",
        "#Split the data into independent 'X' and dependent 'Y' variables\n",
        "X = titanic.iloc[:, 1:8].values \n",
        "Y = titanic.iloc[:, 0].values \n",
        "\n",
        "# Split the dataset into 80% Training set and 20% Testing set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, \n",
        "                                                    random_state = 6, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjPE0-3U_wu2"
      },
      "source": [
        "##LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyPrr8qKAOv3"
      },
      "source": [
        "Create a LOGISTIC REGRESSION classifier, (you may need to modify max_iter). What is\n",
        "your training score? test score? \n",
        "\n",
        "\n",
        "Modified maxtire from defalut value 100 to 24"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGBP-dWW_xbM"
      },
      "source": [
        "#Using Logistic Regression Algorithm to the Training Set\n",
        "log = LogisticRegression(random_state = 0, max_iter=24)\n",
        "log.fit(X_train, Y_train)\n",
        "print('Logistic Regression Training Accuracy:', log.score(X_train, Y_train))\n",
        "print('Logistic Regression Testing Accuracy:', log.score(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R1e2putAW_J"
      },
      "source": [
        "Evaluate the results of this model using classification_report. What additional insight can you\n",
        "glean from the report about the two classes? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6wc_V9dAX23"
      },
      "source": [
        "# Constructing the confusion matrix.\n",
        "cm = confusion_matrix(Y_test, log.predict(X_test)) \n",
        "print('Confusion Matrix :\\n', cm)\n",
        "TN, FP, FN, TP = confusion_matrix(Y_test, log.predict(X_test)).ravel()\n",
        "print('Logistic Regression Testing Accuracy = '  ,(TP + TN) / (TP + TN + FN + FP))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az5yCyuFN7XM"
      },
      "source": [
        "Evaluate the results of this model using confusion_matrix. How many True-Negatives (NonSurvivors) did your model correctly identify? _______. How many actual Non-Survivors were\n",
        "there? _______. That ratio represents what metric from the classification_report?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiukC-xaNegY"
      },
      "source": [
        "# Predictions and Evaluations\n",
        "# Now predict values for the testing data.\n",
        "predictions = log.predict(X_test)\n",
        "\n",
        "# Create a classification report and confusion matrix for the model.\n",
        "\n",
        "print ('Classification Report : \\n',classification_report(Y_test,predictions))\n",
        "\n",
        "# End"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efZA5RdmN0jM"
      },
      "source": [
        "print ('Confusion Matrix : \\n',confusion_matrix(Y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcIjUMDlORAr"
      },
      "source": [
        "##MULTI-LAYER PERCEPTRON\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiWy-ylHOiLO"
      },
      "source": [
        "Create a MULTI-LAYER PERCEPTRON (Neural Network), (you may need to modify\n",
        "max_iter). What is your training score? test score?  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q1u4Ja9Of5l"
      },
      "source": [
        "#mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,75,50), max_iter=300,activation = 'relu',\n",
        "#                               solver='adam',random_state=1,shuffle=True)\n",
        "\n",
        "mlp_classifier = MLPClassifier(random_state=1,shuffle=True)\n",
        "\n",
        "mlp_classifier.fit(X_train, Y_train)\n",
        "mlp_classifier.fit(X_train, Y_train)\n",
        "\n",
        "print('MLP Classifier Training Accuracy:', mlp_classifier.score(X_train, Y_train))\n",
        "print('MLP Classifier Training Accuracy:', mlp_classifier.score(X_test, Y_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z89v3hgFQbdP"
      },
      "source": [
        "Now change the hidden_layer_sizes from the default to [30,30], and refit & score. What are the\n",
        "new scores on training? testing? \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFm5XcRJQf64"
      },
      "source": [
        "mlp_classifier = MLPClassifier(hidden_layer_sizes=(30,30),random_state=1,shuffle=True)\n",
        "\n",
        "mlp_classifier.fit(X_train, Y_train)\n",
        "mlp_classifier.fit(X_train, Y_train)\n",
        "\n",
        "print('MLP Classifier Training Accuracy:', mlp_classifier.score(X_train, Y_train))\n",
        "print('MLP Classifier Training Accuracy:', mlp_classifier.score(X_test, Y_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvXUoMb3Q7W4"
      },
      "source": [
        "How many layers are in your model for b?  Was there improvement?\n",
        "No Improvement in score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTI0-hRbOf17"
      },
      "source": [
        "\n",
        "# Constructing the confusion matrix.\n",
        "cm = confusion_matrix(Y_test, mlp_classifier.predict(X_test)) \n",
        "print('Confusion Matrix :\\n', cm)\n",
        "TN, FP, FN, TP = confusion_matrix(Y_test, mlp_classifier.predict(X_test)).ravel()\n",
        "print('MLP Classifier Testing Accuracy = '  ,(TP + TN) / (TP + TN + FN + FP))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMPOF5oURHEn"
      },
      "source": [
        "#SECTION 4 - MODEL SELECTION\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaTpewRIRNhJ"
      },
      "source": [
        "MLP MODEL SEARCH & SELECTION – try a variety of methods from below, to improve upon\n",
        "your MLP model, creating a model that generalizes well and takes advantage of the entire dataset for\n",
        "model selection. COMMENT your CODE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS9uHV0WRQB9"
      },
      "source": [
        "##Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVgPN8cJRV2g"
      },
      "source": [
        "#Feature Scaling\n",
        "\n",
        "sc = StandardScaler()\n",
        "# calling fit and transform in sequence (using method chaining)\n",
        "X_train = sc.fit_transform(X_train)\n",
        "# same result, but more efficient computation\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-8fBLIXTwpI"
      },
      "source": [
        "mlp_classifier = MLPClassifier(random_state=1,shuffle=True)\n",
        "\n",
        "mlp_classifier.fit(X_train, Y_train)\n",
        "print('MLP Classifier Training Accuracy:', mlp_classifier.score(X_train, Y_train))\n",
        "print('MLP Classifier Training Accuracy:', mlp_classifier.score(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMcnFoVcUQA9"
      },
      "source": [
        "Accuricy is increased after default Feature Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yRsu8WIU7UM"
      },
      "source": [
        "##Architectural options\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfJmh0iAZAyw"
      },
      "source": [
        "##Algorithm options\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Lyj7owMZCLD"
      },
      "source": [
        "##Cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YPQ415uhAww"
      },
      "source": [
        "Cross-Validation in scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoTb8KuRZIY3",
        "outputId": "b1ebcbd3-a587-4cf7-994f-2d8ebcd5c190"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "mlp_classifier = MLPClassifier(random_state=1,shuffle=True)\n",
        "scores = cross_val_score(mlp_classifier, X, Y)\n",
        "\n",
        "print(\"Cross-Validation in scikit-learn\")\n",
        "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean()*100, scores.std()*100))\n"
      ],
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-Validation in scikit-learn\n",
            "76.64 accuracy with a standard deviation of 3.32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "Xx0alQCIhIhT",
        "outputId": "cec1cc29-9f8c-4303-9615-c004f4a6b756"
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "res = cross_validate(mlp_classifier, X, Y, cv=5,\n",
        "                     return_train_score=True)\n",
        "display(res)\n"
      ],
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'fit_time': array([0.85511589, 0.81856441, 0.84038448, 0.84340596, 0.86357665]),\n",
              " 'score_time': array([0.00104594, 0.00106525, 0.00096083, 0.00107455, 0.0012784 ]),\n",
              " 'test_score': array([0.76836158, 0.79096045, 0.80681818, 0.75568182, 0.71022727]),\n",
              " 'train_score': array([0.84113475, 0.81985816, 0.82719547, 0.83994334, 0.82436261])}"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "29bVSHT6h7wo",
        "outputId": "bbd51fbf-4091-402f-b9c9-eb7390ee904f"
      },
      "source": [
        "res_df = pd.DataFrame(res)\n",
        "display(res_df)\n",
        "print(\"Mean times and scores:\\n\", res_df.mean())"
      ],
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.855116</td>\n",
              "      <td>0.001046</td>\n",
              "      <td>0.768362</td>\n",
              "      <td>0.841135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.818564</td>\n",
              "      <td>0.001065</td>\n",
              "      <td>0.790960</td>\n",
              "      <td>0.819858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.840384</td>\n",
              "      <td>0.000961</td>\n",
              "      <td>0.806818</td>\n",
              "      <td>0.827195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.843406</td>\n",
              "      <td>0.001075</td>\n",
              "      <td>0.755682</td>\n",
              "      <td>0.839943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.863577</td>\n",
              "      <td>0.001278</td>\n",
              "      <td>0.710227</td>\n",
              "      <td>0.824363</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit_time  score_time  test_score  train_score\n",
              "0  0.855116    0.001046    0.768362     0.841135\n",
              "1  0.818564    0.001065    0.790960     0.819858\n",
              "2  0.840384    0.000961    0.806818     0.827195\n",
              "3  0.843406    0.001075    0.755682     0.839943\n",
              "4  0.863577    0.001278    0.710227     0.824363"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Mean times and scores:\n",
            " fit_time       0.844209\n",
            "score_time     0.001085\n",
            "test_score     0.766410\n",
            "train_score    0.830499\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIIh7zXshE5C"
      },
      "source": [
        "Stratified K-Fold cross-validation and other strategies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udKj6TkDiCyP",
        "outputId": "48822a31-3dd3-4e4d-9418-8b138fe9af6d"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=5)\n",
        "mlp_classifier = MLPClassifier(random_state=1,shuffle=True)\n",
        "scores = cross_val_score(mlp_classifier, X, Y, cv=kfold)\n",
        "\n",
        "print(\"Cross-Validation with n_splits= 5\")\n",
        "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean()*100, scores.std()*100))"
      ],
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-Validation with n_splits= 5\n",
            "77.89 accuracy with a standard deviation of 6.24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j59Xox9Kib6t",
        "outputId": "e4dde43d-3f9e-444e-ff7a-b9efdb7c70c8"
      },
      "source": [
        "kfold = KFold(n_splits=3)\n",
        "mlp_classifier = MLPClassifier(random_state=1,shuffle=True)\n",
        "scores = cross_val_score(mlp_classifier, X, Y, cv=kfold)\n",
        "\n",
        "print(\"Cross-Validation with n_splits= 3\")\n",
        "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean()*100, scores.std()*100))"
      ],
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-Validation with n_splits= 3\n",
            "79.37 accuracy with a standard deviation of 1.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5_5QUgFitpw",
        "outputId": "668db089-f42a-4cfb-b56d-27bb2846af8e"
      },
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True, random_state=1)\n",
        "mlp_classifier = MLPClassifier(random_state=1,shuffle=True)\n",
        "scores = cross_val_score(mlp_classifier, X, Y, cv=kfold)\n",
        "\n",
        "print(\"Cross-Validation with n_splits= 3\")\n",
        "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean()*100, scores.std()*100))"
      ],
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-Validation with n_splits= 3\n",
            "80.50 accuracy with a standard deviation of 1.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVot1Z5Hi5PT"
      },
      "source": [
        "Leave-one-out cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb8VQDWQi6AQ"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "mlp_classifier = MLPClassifier(random_state=1,shuffle=True)\n",
        "scores = cross_val_score(mlp_classifier, X, Y, cv=loo)\n",
        "\n",
        "print(\"Cross-Validation with LeaveOneOut\")\n",
        "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean()*100, scores.std()*100))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9uKFyAJjRYN"
      },
      "source": [
        "Shuffle-split cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf9_vGzfjUOb"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "shuffle_split = ShuffleSplit(test_size=.5, train_size=.5, n_splits=10)\n",
        "mlp_classifier = MLPClassifier(random_state=1,shuffle=True)\n",
        "scores = cross_val_score(mlp_classifier, X, Y, cv=shuffle_split)\n",
        "\n",
        "print(\"Cross-Validation with ShuffleSplit\")\n",
        "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean()*100, scores.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zT52_vqFjgTq"
      },
      "source": [
        "Cross-validation with groups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKitSdbcjhFd"
      },
      "source": [
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "# create synthetic dataset\n",
        "X_groupKfold, y_groupKfold = make_blobs(n_samples=12, random_state=0)\n",
        "mlp_classifier = MLPClassifier(random_state=1,shuffle=True)\n",
        "groups = [0, 0, 0, 1, 1, 1, 1, 2, 2, 3, 3, 3]\n",
        "scores = cross_val_score(mlp_classifier, X_groupKfold, y_groupKfold, \n",
        "                         groups=groups, cv=GroupKFold(n_splits=3))\n",
        "\n",
        "print(\"Cross-Validation with ShuffleSplit\")\n",
        "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean()*100, scores.std()*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51Uq8Fi4d9rt"
      },
      "source": [
        "##Grid Search\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMxsa1rekTFR"
      },
      "source": [
        "Simple Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84hunkcWe1AY"
      },
      "source": [
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(100,75,50), (50,100,50), (150,100,50)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam'],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "    'max_iter' : [100,300,50]\n",
        "}\n",
        "mlp = MLPClassifier()\n",
        "grid_mlp = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
        "grid_mlp.fit(X_train, Y_train)\n",
        "print(f'Best params: {grid_mlp.best_params_}')\n",
        "print(f'Best score: {grid_mlp.best_score_}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmT4x-gOkY4A"
      },
      "source": [
        "mlp_classifier = MLPClassifier(random_state=1,shuffle=True,activation='tanh', alpha= 0.0001, \n",
        "                               hidden_layer_sizes = (50, 100, 50), learning_rate='adaptive', max_iter= 100,\n",
        "                               solver = 'adam')\n",
        "\n",
        "mlp_classifier.fit(X_train, Y_train)\n",
        "mlp_classifier.fit(X_test, Y_test)\n",
        "print('MLP Classifier Training Accuracy:', mlp_classifier.score(X_train, Y_train))\n",
        "print('MLP Classifier Testing Accuracy:', mlp_classifier.score(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6fI43HilABe"
      },
      "source": [
        "Grid Search with Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-6aTAmhlkit"
      },
      "source": [
        "best_score = 0\n",
        "for max_iter in [ 1, 10, 100]:\n",
        "    for hidden_layer_sizes in [(100,75,50), (50,100,50), (150,100,50)]:\n",
        "        # for each combination of parameters,\n",
        "        # train an MLPClassifier\n",
        "        mpl_classifier = MLPClassifier(max_iter=max_iter, hidden_layer_sizes=hidden_layer_sizes)\n",
        "        # perform cross-validation\n",
        "        scores = cross_val_score(mpl_classifier, X_train, Y_train, cv=5)\n",
        "        # compute mean cross-validation accuracy\n",
        "        score = np.mean(scores)\n",
        "        # if we got a better score, store the score and parameters\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_parameters = {'max_iter': max_iter, 'hidden_layer_sizes': hidden_layer_sizes}\n",
        "# rebuild a model on the combined training and validation set\n",
        "mpl_classifier = MLPClassifier(**best_parameters)\n",
        "mpl_classifier.fit(X_train, Y_train)\n",
        "print('MLP Classifier Training Accuracy:', mlp_classifier.score(X_train, Y_train))\n",
        "print('MLP Classifier Testing Accuracy:', mlp_classifier.score(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jRhIYLeeYqb"
      },
      "source": [
        "##Common hyperparameter options\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS2DSmkbrWvd"
      },
      "source": [
        "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,75,50), max_iter=300,activation = 'relu',\n",
        "                               solver='adam',random_state=1,shuffle=True)\n",
        "mlp_classifier.fit(X_train, Y_train)\n",
        "mlp_classifier.fit(X_test, Y_test)\n",
        "\n",
        "print('MLP Classifier Training Accuracy:', mlp_classifier.score(X_train, Y_train))\n",
        "print('MLP Classifier Training Accuracy:', mlp_classifier.score(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlpaYCQGebov"
      },
      "source": [
        "##Further Feature Engineering or alternative encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7O7saaZ0wlV"
      },
      "source": [
        "**Label Encoding**\n",
        "\n",
        "It is used to transform non-numerical labels to numerical labels (or nominal categorical variables). Numerical labels are always between 0 and n_classes-1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHmNn2vo181_"
      },
      "source": [
        "#Encoding categorical data values (Transforming object data types to integers)\n",
        "labelencoder = LabelEncoder()\n",
        "print ('Before')\n",
        "print(titanic_old['Sex'].unique())\n",
        "print(titanic_old['Embarked'].unique())\n",
        "\n",
        "titanic_old.iloc[:,2]= labelencoder.fit_transform(titanic_old.iloc[:,2].values) #Encode sex column\n",
        "titanic_old.iloc[:,7]= labelencoder.fit_transform(titanic_old.iloc[:,7].values) #Encode embarked\n",
        "\n",
        "print ('After')\n",
        "#Print the NEW unique values in the columns\n",
        "print(titanic_old['Sex'].unique())\n",
        "print(titanic_old['Embarked'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBPg5PKZ2got"
      },
      "source": [
        "**Correlation between features**\n",
        "Non-graphical method : This correlation matrix is to understand the strength between variables. Correlation varies between -1 and +1.\n",
        "\n",
        "-1: Perfect negative linear correlation\n",
        "\n",
        "+1: Perfect positive linear correlation\n",
        "\n",
        "0: No correlation\n",
        "\n",
        "Generally, if the correlation between the two independent variables are high (>= 0.8) then we drop one independent variable otherwise it may lead to multi collinearity problem as both of them contains almost the same information.\n",
        "\n",
        "So do you think we should use both of them as one of them is redundant. While making or training models, we should try to eliminate redundant features as it reduces training time and many such advantages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ353eKd2jI_"
      },
      "source": [
        "\n",
        "sns.heatmap(titanic_old.corr(),annot=True,cmap='RdYlGn',linewidths=0.2) #data.corr()-->correlation matrix\n",
        "fig=plt.gcf()\n",
        "fig.set_size_inches(10,8)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1w61MMc2vjA"
      },
      "source": [
        "**One Hot Encoding**\n",
        "One hot encoding is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction.\n",
        "\n",
        "Suppose we have Sex classes as 'male' and 'female'. One hot encoding will create two columns 'Sex_male' and 'Sex_female' and store the values as binary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjncSJzv2x1k"
      },
      "source": [
        " titanic_encoding= titanic_old.drop([ 'SibSp','Age','Name','Pclass', 'Fare','Parch','Ticket', 'Cabin','PassengerId','Age_bin','Deck'], axis=1)\n",
        "\n",
        "#Remove the rows with missing values\n",
        "titanic_encoding = titanic_old.dropna(subset =['Embarked'])\n",
        "\n",
        "one_hot_encoded_training_predictors = pd.get_dummies(titanic_encoding)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew8oCZFj4kz3"
      },
      "source": [
        "Check Correlation after One hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzOLWE3-2XlS"
      },
      "source": [
        "sns.heatmap(one_hot_encoded_training_predictors.corr(),annot=True,cmap='RdYlGn',linewidths=0.2) #data.corr()-->correlation matrix\n",
        "fig=plt.gcf()\n",
        "fig.set_size_inches(10,8)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}